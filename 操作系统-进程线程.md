# 1. 进程与线程的区别、使用场景


### 线程


Linux下线程用进程PCB模拟描述，也叫轻量级进程


线程是进程内部的一个执行流，也就是线程在进程的地址空间内运行。


一个进程内的所有线程共享进程资源


线程是CPU调度的基本单位（CPU调度是按照PCB进行调度的）


创建，销毁一个线程相较创建，销毁一个进程成本要低（创建进程要创建PCB,虚拟地址空间，创建页表，维护映射，把硬盘的代码数据加载到内存，文件描述符等等，而创建线程只需要一个PCB指向进程的虚拟地址空间即可，同样销毁一个线程只需要销毁PCB即可）


线程间的切换相比于进程间的切换容易的多（进程间的切换，PCB切换，页表切换等等，线程切换PCB切换，页表不切换）


### 进程


进程是拥有一个执行流，或多个执行流的线程组。


进程是一个能独立运行的基本单位，同时也是系统分配资源基本单位。（独立性）


进程是动态执行的程序（创建一个进程要创建PCB描述进程，为进程分配资源，进程可以被调度，被执行。而程序就只是静静躺在硬盘上）（动态性）


任何进程都可以同其他进程一起并发执行(并发性）(并发：一个CPU多个进程，分时切换）


进程间的相互制约，进程具有执行的间断性，进程按照各自独立不可预知的速度向前推进（异步性）（异步性：指进程以不可预知的速度向前推进，内存中的每个进程何时执行，何时暂停，以怎样的速度向前推进，要用多长时间完成等都是不可预知的


### 进程和线程的区别


线程是被CPU调度的基本单位，进程是能独立运行的基本单位，是系统分配资源的基本单位


创建销毁线程要比创建销毁进程成本低的多。（创建进程要，创建PCB,开辟虚拟地址空间，创建页表，维护映射关系，加载硬盘数据到内存，创建文件描述符，等等，而创建线程只要创建一个PCB指向进程的虚拟地址空间即可）


进程拥有自己独立的虚拟地址空间，而一个进程中的多个线程共享进程的虚拟地址空间


线程占用的资源要比进程少


线程缺乏访问控制，进程中的一个线程出错，会终止掉整个进程，从而导致其他线程也凉凉，而一个进程出错，不会影响另一个进程


**线程和进程共享：**


同一地址空间      (堆，代码段，数据段，环境变量，页表） 
文件描述符表 
每种信号的处理方式 
当前工作目录 
用户id和组id


**线程和进程私有：**


私有栈结构（保存临时数据，保证线程执行时不相互影响）
上下文数据（CPU调度切换数据保存）
调度优先级
errno
信号屏蔽字


# 2. 进程的状态


**Linux进程状态：R (TASK_RUNNING)，可执行状态。**


只有在该状态的进程才可能在CPU上运行。而同一时刻可能有多个进程处于可执行状态，这些进程的task_struct结构（进程控制块）被放入对应CPU的可执行队列中（一个进程最多只能出现在一个CPU的可执行队列中）。进程调度器的任务就是从各个CPU的可执行队列中分别选择一个进程在该CPU上运行。


很多操作系统教科书将正在CPU上执行的进程定义为RUNNING状态、而将可执行但是尚未被调度执行的进程定义为READY状态，这两种状态在linux下统一为 TASK_RUNNING状态。


  


**Linux进程状态：S (TASK_INTERRUPTIBLE)，可中断的睡眠状态。**


处于这个状态的进程因为等待某某事件的发生（比如等待socket连接、等待信号量），而被挂起。这些进程的task_struct结构被放入对应事件的等待队列中。当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程将被唤醒。


通过ps命令我们会看到，一般情况下，进程列表中的绝大多数进程都处于TASK_INTERRUPTIBLE状态（除非机器的负载很高）。毕竟CPU就这么一两个，进程动辄几十上百个，如果不是绝大多数进程都在睡眠，CPU又怎么响应得过来。


  


**Linux进程状态：D (TASK_UNINTERRUPTIBLE)，不可中断的睡眠状态。**


与TASK_INTERRUPTIBLE状态类似，进程处于睡眠状态，但是此刻进程是不可中断的。不可中断，指的并不是CPU不响应外部硬件的中断，而是指进程不响应异步信号。  
绝大多数情况下，进程处在睡眠状态时，总是应该能够响应异步信号的。否则你将惊奇的发现，kill -9竟然杀不死一个正在睡眠的进程了！于是我们也很好理解，为什么ps命令看到的进程几乎不会出现TASK_UNINTERRUPTIBLE状态，而总是TASK_INTERRUPTIBLE状态。


**而TASK_UNINTERRUPTIBLE状态存在的意义就在于，内核的某些处理流程是不能被打断的**。如果响应异步信号，程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入的流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程就被中断了。（参见《linux内核异步中断浅析》）  
在进程对某些硬件进行操作时（比如进程调用read系统调用对某个设备文件进行读操作，而read系统调用最终执行到对应设备驱动的代码，并与对应的物理设备进行交互），可能需要使用TASK_UNINTERRUPTIBLE状态对进程进行保护，以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态。这种情况下的TASK_UNINTERRUPTIBLE状态总是非常短暂的，通过ps命令基本上不可能捕捉到。


linux系统中也存在容易捕捉的TASK_UNINTERRUPTIBLE状态。执行vfork系统调用后，父进程将进入TASK_UNINTERRUPTIBLE状态，直到子进程调用exit或exec（参见《神奇的vfork》）。  
通过下面的代码就能得到处于TASK_UNINTERRUPTIBLE状态的进程：


#include void main() { if (!vfork()) sleep(100); }


  
编译运行，然后ps一下：


kouu@kouu-one:~/test$ ps -ax | grep a\.out 4371 pts/0 D+ 0:00 ./a.out 4372 pts/0 S+ 0:00 ./a.out 4374 pts/1 S+ 0:00 grep a.out


  
然后我们可以试验一下TASK_UNINTERRUPTIBLE状态的威力。不管kill还是kill -9，这个TASK_UNINTERRUPTIBLE状态的父进程依然屹立不倒。


  


  


上面我们介绍了Linux进程的R、S、D三种状态，这里接着上面的文章介绍另外三个状态。


  


**Linux进程状态：T (TASK_STOPPED or TASK_TRACED)，暂停状态或跟踪状态。**


向进程发送一个SIGSTOP信号，它就会因响应该信号而进入TASK_STOPPED状态（除非该进程本身处于TASK_UNINTERRUPTIBLE状态而不响应信号）。（SIGSTOP与SIGKILL信号一样，是非常强制的。不允许用户进程通过signal系列的系统调用重新设置对应的信号处理函数。）  
向进程发送一个SIGCONT信号，可以让其从TASK_STOPPED状态恢复到TASK_RUNNING状态。


当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于TASK_TRACED状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。


对于进程本身来说，TASK_STOPPED和TASK_TRACED状态很类似，都是表示进程暂停下来。  
而TASK_TRACED状态相当于在TASK_STOPPED之上多了一层保护，处于TASK_TRACED状态的进程不能响应SIGCONT信号而被唤醒。只能等到调试进程通过ptrace系统调用执行PTRACE_CONT、PTRACE_DETACH等操作（通过ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复TASK_RUNNING状态。


  


**Linux进程状态：Z (TASK_DEAD - EXIT_ZOMBIE)，退出状态，进程成为僵尸进程。**


进程在退出的过程中，处于TASK_DEAD状态。


在这个退出过程中，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外。于是进程就只剩下task_struct这么个空壳，故称为僵尸。  
之所以保留task_struct，是因为task_struct里面保存了进程的退出码、以及一些统计信息。而其父进程很可能会关心这些信息。比如在shell中，$?变量就保存了最后一个退出的前台进程的退出码，而这个退出码往往被作为if语句的判断条件。  
当然，内核也可以将这些信息保存在别的地方，而将task_struct结构释放掉，以节省一些空间。但是使用task_struct结构更为方便，因为在内核中已经建立了从pid到task_struct查找关系，还有进程间的父子关系。释放掉task_struct，则需要建立一些新的数据结构，以便让父进程找到它的子进程的退出信息。


父进程可以通过wait系列的系统调用（如wait4、waitid）来等待某个或某些子进程的退出，并获取它的退出信息。然后wait系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉。  
子进程在退出的过程中，内核会给其父进程发送一个信号，通知父进程来“收尸”。这个信号默认是SIGCHLD，但是在通过clone系统调用创建子进程时，可以设置这个信号。


  


通过下面的代码能够制造一个EXIT_ZOMBIE状态的进程：


#include void main() { if (fork()) while(1) sleep(100); }


  
编译运行，然后ps一下：


kouu@kouu-one:~/test$ ps -ax | grep a\.out 10410 pts/0 S+ 0:00 ./a.out 10411 pts/0 Z+ 0:00 [a.out] 10413 pts/1 S+ 0:00 grep a.out


只要父进程不退出，这个僵尸状态的子进程就一直存在。那么如果父进程退出了呢，谁又来给子进程“收尸”？  
当进程退出的时候，会将它的所有子进程都托管给别的进程（使之成为别的进程的子进程）。托管给谁呢？可能是退出进程所在进程组的下一个进程（如果存在的话），或者是1号进程。所以每个进程、每时每刻都有父进程存在。除非它是1号进程。


1号进程，pid为1的进程，又称init进程。  
linux系统启动后，第一个被创建的用户态进程就是init进程。它有两项使命：  
1、执行系统初始化脚本，创建一系列的进程（它们都是init进程的子孙）；  
2、在一个死循环中等待其子进程的退出事件，并调用waitid系统调用来完成“收尸”工作；  
init进程不会被暂停、也不会被杀死（这是由内核来保证的）。它在等待子进程退出的过程中处于TASK_INTERRUPTIBLE状态，“收尸”过程中则处于TASK_RUNNING状态。


  


**Linux进程状态：X (TASK_DEAD - EXIT_DEAD)，退出状态，进程即将被销毁。**


而进程在退出过程中也可能不会保留它的task_struct。比如这个进程是多线程程序中被detach过的进程（进程？线程？参见《linux线程浅析》）。或者父进程通过设置SIGCHLD信号的handler为SIG_IGN，显式的忽略了SIGCHLD信号。（这是posix的规定，尽管子进程的退出信号可以被设置为SIGCHLD以外的其他信号。）  
此时，进程将被置于EXIT_DEAD退出状态，这意味着接下来的代码立即就会将该进程彻底释放。所以EXIT_DEAD状态是非常短暂的，几乎不可能通过ps命令捕捉到。


![三种状态转换](http://upload-images.jianshu.io/upload_images/1485056-efde09b1217348ee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


创建状态：进程在创建时需要申请一个空白PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态


就绪状态：进程已经准备好，已分配到所需资源，只要分配到CPU就能够立即运行


执行状态：进程处于就绪状态被调度后，进程进入执行状态


阻塞状态：正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用


终止状态：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行


    如果进程运行时间片使用完也会进入就绪状态。
    另外为用户观察需要，进程还有挂起和激活两种操作。挂起后进程处于静止状态进程不再被系统调用，对于操作是激活操作。


# 3. 操作系统调度算法


在操作系统中存在多种调度算法，其中有的调度算法适用于作业调度，有的调度算法适用于进程调度，有的调度算法两者都适用。下面介绍几种常用的调度算法。


## 先来先服务(FCFS)调度算法


FCFS调度算法是一种最简单的调度算法，该调度算法既可以用于作业调度也可以用于进程调度。在作业调度中，算法每次从后备作业队列中选择最先进入该队列的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。  
  
在进程调度中，FCFS调度算法每次从就绪队列中选择最先进入该队列的进程，将处理机分配给它，使之投入运行，直到完成或因某种原因而阻塞时才释放处理机。  
  
下面通过一个实例来说明FCFS调度算法的性能。假设系统中有4个作业，它们的提交时间分别是8、8.4、8.8、9，运行时间依次是2、1、0.5、0.2，系统釆用FCFS调度算法，这组作业的平均等待时间、平均周转时间和平均带权周转时间见表2-3。  


  
FCFS调度算法属于不可剥夺算法。从表面上看，它对所有作业都是公平的，但若一个长作业先到达系统，就会使后面许多短作业等待很长时间，因此它不能作为分时系统和实时系统的主要调度策略。但它常被结合在其他调度策略中使用。例如，在使用优先级作为调度策略的系统中，往往对多个具有相同优先级的进程按FCFS原则处理。  
  
FCFS调度算法的特点是算法简单，但效率低；对长作业比较有利，但对短作业不利（相对SJF和高响应比）；有利于CPU繁忙型作业，而不利于I/O繁忙型作业。


## 短作业优先(SJF)调度算法


短作业（进程）优先调度算法是指对短作业（进程）优先调度的算法。短作业优先(SJF)调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法，则是从就绪队列中选择一个估计运行时间最短的进程，将处理机分配给它，使之立即执行，直到完成或发生某事件而阻塞时，才释放处理机。  
  
例如，考虑表2-3中给出的一组作业，若系统釆用短作业优先调度算法，其平均等待时间、平均周转时间和平均带权周转时间见表2-4。  


  
SJF调度算法也存在不容忽视的缺点：


-   该算法对长作业不利，由表2-3和表2-4可知，SJF调度算法中长作业的周转时间会增加。更严重的是，如果有一长作业进入系统的后备队列，由于调度程序总是优先调度那些 (即使是后进来的）短作业，将导致长作业长期不被调度（**“饥饿”现象，注意区分“死锁”**。后者是系统环形等待，前者是调度策略问题）。
-   该算法完全未考虑作业的紧迫程度，因而不能保证紧迫性作业会被及时处理。
-   由于作业的长短只是根据用户所提供的估计执行时间而定的，而用户又可能会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先调度。


  
注意，SJF调度算法的平均等待时间、平均周转时间最少。


## 优先级调度算法


优先级调度算法又称优先权调度算法，该算法既可以用于作业调度，也可以用于进程调度，该算法中的优先级用于描述作业运行的紧迫程度。  
  
在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最髙的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。  
  
根据新的更高优先级进程能否抢占正在执行的进程，可将该调度算法分为：


-   非剥夺式优先级调度算法。当某一个进程正在处理机上运行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在运行的进程继续运行，直到由于其自身的原因而主动让出处理机时（任务完成或等待事件），才把处理机分配给更为重要或紧迫的进程。
-   剥夺式优先级调度算法。当一个进程正在处理机上运行时，若有某个更为重要或紧迫的进程进入就绪队列，则立即暂停正在运行的进程，将处理机分配给更重要或紧迫的进程。


  
而根据进程创建后其优先级是否可以改变，可以将进程优先级分为以下两种：


-   静态优先级。优先级是在创建进程时确定的，且在进程的整个运行期间保持不变。确定静态优先级的主要依据有进程类型、进程对资源的要求、用户要求。
-   动态优先级。在进程运行过程中，根据进程情况的变化动态调整优先级。动态调整优先级的主要依据为进程占有CPU时间的长短、就绪进程等待CPU时间的长短。


## 高响应比优先调度算法


高响应比优先调度算法主要用于作业调度，***该算法是对FCFS调度算法和SJF调度算法的一种综合平衡***，同时考虑每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。  
  
响应比的变化规律可描述为：  
![](http://c.biancheng.net/cpp/uploads/allimg/140629/1-140629155214919.png)  
  
根据公式可知：


-   当作业的等待时间相同时，则要求服务时间越短，其响应比越高，有利于短作业。
-   当要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高，因而它实现的是先来先服务。
-   对于长作业，作业的响应比可以随等待时间的增加而提高，当其等待时间足够长时，其响应比便可升到很高，从而也可获得处理机。克服了饥饿状态，兼顾了长作业。


## 时间片轮转调度算法


时间片轮转调度算法主要适用于分时系统。在这种算法中，系统将所有就绪进程按到达时间的先后次序排成一个队列，进程调度程序总是选择就绪队列中第一个进程执行，即先来先服务的原则，但仅能运行一个时间片，如100ms。在使用完一个时间片后，即使进程并未完成其运行，它也必须释放出（被剥夺）处理机给下一个就绪的进程，而被剥夺的进程返回到就绪队列的末尾重新排队，等候再次运行。  
  
在时间片轮转调度算法中，时间片的大小对系统性能的影响很大。如果时间片足够大，以至于所有进程都能在一个时间片内执行完毕，则时间片轮转调度算法就退化为先来先服务调度算法。如果时间片很小，那么处理机将在进程间过于频繁切换，使处理机的开销增大，而真正用于运行用户进程的时间将减少。因此时间片的大小应选择适当。  
  
时间片的长短通常由以下因素确定：系统的响应时间、就绪队列中的进程数目和系统的处理能力。


## 多级反馈队列调度算法（集合了前几种算法的优点）


多级反馈队列调度算法是时间片轮转调度算法和优先级调度算法的综合和发展，如图2-5 所示。通过动态调整进程优先级和时间片大小，多级反馈队列调度算法可以兼顾多方面的系统目标。例如，为提高系统吞吐量和缩短平均周转时间而照顾短进程；为获得较好的I/O设备利用率和缩短响应时间而照顾I/O型进程；同时，也不必事先估计进程的执行时间。  
  


![](http://c.biancheng.net/cpp/uploads/allimg/140629/1-140629155KQ11.jpg)  
图2-5 多级反馈队列调度算法


  
多级反馈队列调度算法的实现思想如下：


1.  应设置多个就绪队列，并为各个队列赋予不同的优先级，第1级队列的优先级最高，第2级队列次之，其余队列的优先级逐次降低。
2.  赋予各个队列中进程执行时间片的大小也各不相同，在优先级越高的队列中，每个进程的运行时间片就越小。例如，第2级队列的时间片要比第1级队列的时间片长一倍， ……第i+1级队列的时间片要比第i级队列的时间片长一倍。
3.  当一个新进程进入内存后，首先将它放入第1级队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；**如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第2级队列的末尾**，再同样地按FCFS 原则等待调度执行；如果它在第2级队列中运行一个时间片后仍未完成，再以同样的方法放入第3级队列……如此下去，当一个长进程从第1级队列依次降到第 n 级队列后，在第 n 级队列中便釆用时间片轮转的方式运行。
4.  仅当第1级队列为空时，调度程序才调度第2级队列中的进程运行；仅当第1 ~ (i-1)级队列均为空时，才会调度第i级队列中的进程运行。如果处理机正在执行第i级队列中的某进程时，又有新进程进入优先级较高的队列（第 1 ~ (i-1)中的任何一个队列），则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i级队列的末尾，把处理机分配给新到的更高优先级的进程。


  
多级反馈队列的优势有：


-   终端型作业用户：短作业优先。
-   短批处理作业用户：周转时间较短。
-   长批处理作业用户：经过前面几个队列得到部分执行，不会长期得不到处理。






#  4. 协程


**协程，英文Coroutines，是一种比线程更加轻量级的存在。**正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程。


最重要的是，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。


这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。
最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。


第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。


因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。


Python对协程的支持是通过generator实现的。


在generator中，我们不但可以通过`for`循环来迭代，还可以不断调用`next()`函数获取由`yield`语句返回的下一个值。


但是Python的`yield`不但可以返回一个值，它还可以接收调用者发出的参数。




![](http://5b0988e595225.cdn.sohucs.com/images/20180622/8081394d462340cebbf7a31106f63474.png)


# 5. 线程实现的方式


在引入线程的操作系统中，进程是资源分配的基本单位，线程是独立调度的基本单位。在同一进程中，线程的切换不会引起进程切换。在不同进程中进行线程切换,如从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。


线程分为两种：


**用户级线程(User-Level Thread, ULT)**        由应用程序所支持的线程实现, 对内核不可见
**内核级线程(Kernel-Level Thread, KLT)**        内核级线程又称为内核支持的线程
组合线程(Hybrid Multithreading)是一种别的实现方式而不是线程的种类。


## 用户级线程
线程的用户级线程实现方式
有关线程管理的所有工作都由应用程序完成，**内核意识不到多线程的存在**。


用户级线程仅存在于用户空间中，此类线程的**创建、撤销、线程之间的同步与通信**功能，都**无法利用系统调用**来实现。


应用程序需要通过使用线程库来控制线程。 通常，应用程序从单线程起始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生创建一个在相同进程中运行的新线程。由于线程在进程内切换的规则远比进程调度和切换的规则简单，不需要进行用户态/核心态切换，所以切换速度快。


用户线程多见于一些历史悠久的操作系统，例如Unix操作系统。


因为用户级线程驻留在用户空间，且管理和控制它们的线程也在用户空间，每个线程并不具有自身的线程上下文，所以它们对于操作系统是不可见的，这也就是它无法被调度到处理器内核的原因。


操作系统认为所有的进程都是单线程的，因此，就线程的同时执行而言，任意给定时刻每个进程只能够有一个线程在运行，而且只有一个处理器内核会被分配给该进程。对于一个进程，可能有成千上万个用户级线程，但是它们对系统资源没有影响。运行时库调度并分派这些线程。


下图说明了用户级线程的实现方式,


![è¿™é‡Œå†™å›¾ç‰‡æè¿°](https://img-blog.csdn.net/20180320042241255?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3UwMTMwMDc5MDA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)


如同在图中看到的那样，库调度器从进程的多个线程中选择一个线程，然后该线程和该进程与一个内核线程关联起来。内核线程将被操作系统调度器指派到处理器内核。用户级线程是一种”多对一”的线程映射。


用户线程的优点
可以在不支持线程的操作系统中实现。
创建和销毁线程、线程切换代价等线程管理的代价比内核线程少, 因为保存线程状态的过程和调用程序都只是本进程空间的操作
允许每个进程定制自己的调度算法，线程管理比较灵活。
线程能够利用的表空间和堆栈空间比内核级线程多
不需要trap，不需要上下文切换（context switch），也不需要对内存高速缓存进行刷新，使得线程调用非常快捷
线程的调度不需要内核直接参与，控制简单。
用户线程的缺点
线程发生I/O或页面故障引起的阻塞时，如果调用阻塞系统调用则内核由于不知道有多线程的存在，而会阻塞整个进程从而阻塞所有线程, 因此同一进程中只能同时有一个线程在运行（在用户级线程中，每个进程里的线程表在运行时由系统管理。当一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程所需的信息，与内核在进程表中存放的进程的信息完全一样）。
页面失效也会产生类似的问题。
一个单独的进程内部，没有时钟中断，所以不可能用轮转调度的方式调度线程。
资源调度按照进程进行，多个处理机下，同一个进程中的线程只能在同一个处理机下分时复用，因此对于多线程并不能被多核系统加速。


## 内核级线程
线程的内核级线程实现
内核线程建立和销毁都是在内核的支持下运行，由操作系统负责管理，通过系统调用完成的。


线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口。内核为进程及其内部的每个线程维护上下文信息，调度也是在内核基于线程架构的基础上完成。


![è¿™é‡Œå†™å›¾ç‰‡æè¿°](https://img-blog.csdn.net/20180320044427270?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3UwMTMwMDc5MDA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)


内核线程驻留在内核空间，它们是内核对象。操作系统调度器管理、调度并分派这些线程。运行时库为每个用户级线程请求一个内核级线程，将用户进程映射或绑定到上面。用户线程在其生命期内都会绑定到该内核线程。一旦用户线程终止，两个线程都将离开系统。这被称作”一对一”线程映射。


内核空间内为每一个内核支持线程设置了一个线程控制块（TCB），内核根据该控制块，感知线程的存在，并进行控制。


操作系统的内存管理和调度子系统必须要考虑到数量巨大的用户级线程。您必须了解每个进程允许的线程的最大数目是多少。操作系统为每个线程创建上下文。进程的每个线程在资源可用时都可以被指派到处理器内核，这些线程可以在全系统内进行资源的竞争。


内核线程的特点
当某个线程希望创建一个新线程或撤销一个已有线程时，它进行一个系统调用


内核线程的优点
多处理器系统中，内核能够并行执行同一进程内的多个线程。
如果进程中的一个线程被阻塞，能够切换同一进程内的其他线程继续执行（用户级线程的一个缺点）。
所有能够阻塞线程的调用都以系统调用的形式实现，代价较大。
当一个线程阻塞时，内核根据选择可以运行另一个进程的线程。
信号是发给进程而不是线程的，当一个信号到达时，应该由哪一个线程处理它？线程可以“订阅”它们感兴趣的信号（订阅发布模型）。


## 用户级线程和内核级线程的区别


内核支持线程是OS内核可感知的，而用户级线程是OS内核不可感知的。
用户级线程的创建、撤消和调度**不需要OS内核的支持**，是在**语言（如Java）这一级处理**的； 
而内核支持线程创建、撤消和调度都需OS内核提供支持，而且与进程的创建、撤消和调度大体是相同的。
用户级线程执行系统调用指令时将导致其所属进程被中断，而内核支持线程执行系统调用指令时，只导致该线程被中断。
在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度。
用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。


## 组合方式


在一些系统中，使用组合方式的多线程实现, 线程创建完全在用户空间中完成，线程的调度和同步也在应用程序中进行。一个应用程序中的多个用户级线程被映射到一些（小于或等于用户级线程的数目）内核级线程上。


下图说明了用户级与内核级的组合实现方式, 在这种模型中，每个内核级线程有一个可以轮流使用的用户级线程集合


![è¿™é‡Œå†™å›¾ç‰‡æè¿°](https://img-blog.csdn.net/20180320045459981?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3UwMTMwMDc5MDA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)


## 轻量级进程LWP


既然称作轻量级进程，可见其本质仍然是进程，与普通进程相比，**LWP与其它进程共享所有（或大部分）逻辑地址空间和系统资源**，一个进程可以创建多个LWP，这样它们共享大部分资源；LWP有它自己的进程标识符，并和其他进程有着父子关系；这是和类Unix操作系统的系统调用vfork()生成的进程一样的。LWP由内核管理并像普通进程一样被调度。Linux内核是支持LWP的典型例子。Linux内核在 2.0.x版本就已经实现了轻量进程，应用程序可以通过一个统一的clone()系统调用接口，用不同的参数指定创建轻量进程还是普通进程，通过参数决定子进程和父进程共享的资源种类和数量，这样就有了轻重之分。在内核中， clone()调用经过参数传递和解释后会调用do_fork()，这个核内函数同时也是fork()、vfork()系统调用的最终实现。


在大多数系统中，LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息，而这也是它之所以被称为_轻量级_的原因。


 **POSIX线程库实现** 
 
posix线程调度是一个混合模型，很灵活，足以在标准的特定实现中支持用户级和内核级的线程。模型中包括两级调度--线程及和内核实体级。线程级与用户级线程类似，内核实体由内核调度。由线程库来决定它需要多少内核实体，以及他们是如何映射的。


POSIX 引入了一个线程调度竞争范围(thread-scheduling contention scope)的概念，这个. 概念赋予了程序员一些控制权，使它们可以控制怎样将内核实体映射为线程。线程的contentionscope属性可是PTHREAD_SCOPE_PROCESS,也可以是PTHREAD_SCOPE_SYSTEM。带有PTHREAD_SCOPE_PROCESS属性的线程与它所在的进程中的其他线程竞争处理器资源。带有PTHREAD_SCOPE_SYSTEM属性的线程很像内核级线程，他们在全系统的范围内竞争处理器资源。POSIX的一种映射方式将PTHREAD_SCOPE_SYSTEM线程和内核实体之间绑定起来。


**clone()** 是Linux为创建线程设计的（虽然也可以用clone创建进程）。所以可以说clone是fork的升级版本，不仅可以创建进程或者线程，还可以 **指定创建新的命名空间（namespace）、有选择的继承父进程的内存、甚至可以将创建出来的进程变成父进程的兄弟进程**等等。


**clone()函数** 功能强大，带了众多参数，它提供了一个非常灵活自由的常见进程的方法。因此由他创建的进程要比前面2种方法要复杂。**clone可以让你有选择性的继承父进程的资源**，你可以选择想vfork一样和父进程共享一个虚存空间，从而使创造的是线程，你也可以不和父进程共享，你甚至可以选择创造出来的进程和父进程不再是父子关系，而是兄弟关系。


# 6. 进程同步的四种方法


### 1、临界区（Critical Section）:通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。


**优点：**保证在某一时刻只有一个线程能访问数据的简便办法


**缺点：**虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。


### 2、互斥量（Mutex）:为协调共同对一个共享资源的单独访问而设计的。


互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。


**优点：**使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。


**缺点：**①互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。
②通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种资源计数器。


### 3、信号量（Semaphore）:为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。


**优点：**适用于对Socket（套接字）程序中线程的同步。（例如，网络上的HTTP服务器要对同一时间内访问同一页面的用户数加以限制，只有不大于设定的最大用户数目的线程能够进行访问，而其他的访问企图则被挂起，只有在有用户退出对此页面的访问后才有可能进入。）


**缺点**：①信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点；
②信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重了程序员的编码负担；
③核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。


 


### 4、事件（Event）: 用来通知线程有一些事件已发生，从而启动后继任务的开始。


**优点：**事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程中的线程同步操作。
缺点：


总结：


①**临界区不是内核对象**，只能用于进程内部的线程同步，是**用户方式**的同步。互斥、信号量是内核对象可以用于不同进程之间的线程同步（跨进程同步）。
②互斥其实是信号量的一种特殊形式。互斥可以保证在某一时刻只有一个线程可以拥有临界资源。信号量可以保证在某一时刻有指定数目的线程可以拥有临界资源。




![](https://img-blog.csdn.net/20171121130628916)


# 6. 进程同步的经典问题


**一、生产者与消费者问题**


问题描述：一组生产者进程和一组消费者进程共享一块初始为空，大小确定的缓冲区，只有当缓冲区为满时，生产者进程才可以把信息放入缓冲区，否则就要等待；只有缓存区不为空时，消费者进程才能从中取出消息，否则就要等待。缓冲区一次只能一个进程访问（临界资源）。


问题分析：生产者与消费者进程对缓冲区的访问是互斥关系，而生产者与消费者本身又存在同步关系，即必须生成之后才能消费。因而对于缓冲区的访问设置一个互斥量，再设置两个信号量一个记录空闲缓冲区单元，一个记录满缓冲区单元来实现生产者与消费者的同步。


        semaphore mutex=1;
        semaphore full=0;         //满缓冲区单元
        semaphore empty=N;    //空闲缓冲区单元


        prodecer()
        {
            while(1)
            {
                  P(empty);          
                  P(mutex);
                  add_source++;
                  V(mutex);
                  V(full);      
            }    
        }        


        consumer()
        {
            while(1)
           {
                 P(full);
                 P(mutex);
                 add_source--;
                 V(mutex);
                 V(empty);     
            }    
        }




**二、读者与写者问题**


问题描述：有读者与写者两个并发进程共享一个数据，两个或以上的读进程可以访问数据，但是一个写者进程访问数据与其他进程都互斥。


问题分析：读者与写者是互斥关系，写者与写者是互斥关系，读者与读者是同步关系。因而需要一个互斥量实现读与写和写与写互斥，一个读者的访问计数和实现对计数的互斥。


问题解决：三种伪代码实现


1、读者优先


  读者优先，只要有读者源源不断，写者就得不到资源。容易造成写者饥饿。


        int count=0;
        semaphore mutex=1;    //读者计数锁
        semaphore rw=1;        //资源访问锁


        writer()
        {
            while(1)
            {
                P(rw);
                writing sth;
                V(rw);
            }
        }


        reader()
        {
            while(1)
            {
                P(mutex);
                if(count==0)
                    P(rw);
                count++;
                V(mutex);
                reading sth;
                P(mutex);
                count--;
                if(count==0)
                    V(rw);
                V(mutex)；
            }
        }
   
   
2、读写公平


  读者与写者公平抢占资源，但是只要之前已经排队的读者，就算写者获取的资源，也要等待所有等待的读者进程结束。


    //读写公平
    int count=0；
    semaphore mutex=1;    //读者计数锁
    semaphore rw=1;        //资源访问锁
    semaphore w=1;        //读写公平抢占锁
    writer()
    {
        while(1)
        {
            P(w);
            P(rw);
            writing sth;
            V(rw);
            V(w);
        }
    }
    
    reader()
    {
        while(1)
        {
            P(w);
            P(mutex);
            if(count==0)
                P(rw);
            count++;
            V(mutex);
            V(w);
            reading sth;
            P(mutex);
            count--;
            if(count==0)
                V(rw);
            V(mutex);        
        }
    }


**三、哲学家就餐问题**


问题描述：一张圆桌上坐着五名哲学家，每两名哲学家之间的桌子摆一根筷子，哲学家只有同时拿起左右两根筷子时才可以用餐，用餐完了筷子放回原处。


问题分析：这里五名哲学家就是五个进程，五根筷子是需要获取的资源。可以定义互斥数组用于表示五根筷子的互斥访问，为了防止哲学家个取一根筷子出现死锁，需要添加一定的限制条件。一种方法是限制仅当哲学家左右筷子均可以用时，才拿起筷子，这里需要一个互斥量来限制获取筷子不会出现竞争。


问题解决：一次仅能一个哲学家拿起筷子，效率比较低  


        semaphore chopstick[5]={1,1,1,1,1};
        semaphore mutex=1;
        pi()
        {
            while(1)
            {
                P(mutex);
                P(chopstick[i]);
                P(chopstick[(i+1)%5]);
                V(mutex);
                
                eating;
                
                V(chopstick[i]);
                V(chopstick[(i+1)%5]);
            }
        }


# 7. 进程间通信


1. 管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。  
2. 命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。  
3. 消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。  
4. **共享存储SharedMemory**：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。  


![](https://upload-images.jianshu.io/upload_images/944365-c2605f7bb79b0865.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)


![](https://upload-images.jianshu.io/upload_images/944365-7f0c6c23bb3d1cb9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)


5. 信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。  
6. 套接字Socket：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。  
7. 信号 ( signal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。




# 8. 死锁必要条件


   **概念：** 多个并发进程因争夺系统资源而产生相互等待的现象。
   **原理：** 当一组进程中的每个进程都在等待某个事件发生，而只有这组进程中的其他进程才能触发该事件，这就称这组进程发生了死锁。
   **本质原因：**
       1）、系统资源有限。
       2）、进程推进顺序不合理。


**死锁产生的4个必要条件**
    1、**互斥**：某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束。
    2、**占有且等待**：一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源。
    3、**不可抢占**：别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。
    4、** **：存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源。
       当以上四个条件均满足，必然会造成死锁，发生死锁的进程无法进行下去，它们所持有的资源也无法释放。这样会导致CPU的吞吐量下降。所以死锁情况是会浪费系统资源和影响计算机的使用性能的。那么，解决死锁问题就是相当有必要的了。




# 9. 解决死锁策略


## 1、死锁预防 ----- 确保系统永远不会进入死锁状态


   产生死锁需要四个条件，那么，只要这四个条件中至少有一个条件得不到满足，就不可能发生死锁了。由于互斥条件是非共享资源所必须的，不仅不能改变，还应加以保证，所以，主要是破坏产生死锁的其他三个条件。
   
**a、破坏“占有且等待”条件**
     方法1：所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源。
         优点：简单易实施且安全。
         缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，严重降低了资源的利用率，造成资源浪费。
                  使进程经常发生饥饿现象。
     方法2：该方法是对第一种方法的改进，允许进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到的已经使用完毕的资源，然后再去请求新的资源。这样的话，资源的利用率会得到提高，也会减少进程的饥饿问题。
     
**b、破坏“不可抢占”条件**
      当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。这就意味着进程已占有的资源会被短暂地释放或者说是被抢占了。
      该种方法实现起来比较复杂，且代价也比较大。释放已经保持的资源很有可能会导致进程之前的工作实效等，反复的申请和释放资源会导致进程的执行被无限的推迟，这不仅会延长进程的周转周期，还会影响系统的吞吐量。
      
**c、破坏“循环等待”条件**
     可以通过定义资源类型的线性顺序来预防，可将每个资源编号，当一个进程占有编号为i的资源时，那么它下一次申请资源只能申请编号大于i的资源。如图所示：


这样虽然避免了循环等待，但是这种方法是比较低效的，资源的执行速度回变慢，并且可能在没有必要的情况下拒绝资源的访问，比如说，进程c想要申请资源1，如果资源1并没有被其他进程占有，此时将它分配个进程c是没有问题的，但是为了避免产生循环等待，该申请会被拒绝，这样就降低了资源的利用率
！


## 2、避免死锁 ----- 在使用前进行判断，只允许不会产生死锁的进程申请资源


的死锁避免是利用额外的检验信息，在分配资源时判断是否会出现死锁，只在不会出现死锁的情况下才分配资源。
两种避免办法：
    1、如果一个进程的请求会导致死锁，则不启动该进程
    2、如果一个进程的增加资源请求会导致死锁 ，则拒绝该申请。
避免死锁的具体实现通常利用银行家算法
    银行家算法
a、银行家算法的相关数据结构
    **可利用资源向量Available**：用于表示系统里边各种资源剩余的数目。由于系统里边拥有的资源通常都是有很多种（假设有m种），所以，我们用一个有m个元素的数组来表示各种资源。数组元素的初始值为系统里边所配置的该类全部可用资源的数目，其数值随着该类资源的分配与回收动态地改变。
    **最大需求矩阵Max**：用于表示各个进程对各种资源的额最大需求量。进程可能会有很多个（假设为n个），那么，我们就可以用一个nxm的矩阵来表示各个进程多各种资源的最大需求量
    **分配矩阵Allocation**：顾名思义，就是用于表示已经分配给各个进程的各种资源的数目。也是一个nxm的矩阵。
    **需求矩阵Need**：用于表示进程仍然需要的资源数目，用一个nxm的矩阵表示。系统可能没法一下就满足了某个进程的最大需求（通常进程对资源的最大需求也是只它在整个运行周期中需要的资源数目，并不是每一个时刻都需要这么多），于是，为了进程的执行能够向前推进，通常，系统会先分配个进程一部分资源保证进程能够执行起来。那么，进程的最大需求减去已经分配给进程的数目，就得到了进程仍然需要的资源数目了。


银行家算法通过对进程需求、占有和系统拥有资源的实时统计，确保系统在分配给进程资源不会造成死锁才会给与分配。
死锁避免的优点：不需要死锁预防中的抢占和重新运行进程，并且比死锁预防的限制要少。
死锁避免的限制：
    必须事先声明每个进程请求的最大资源量
    考虑的进程必须无关的，也就是说，它们执行的顺序必须没有任何同步要求的限制
    分配的资源数目必须是固定的。
    在占有资源时，进程不能退出


# 10. 虚拟内存、内存分页


为了解决交换系统存在的缺陷，分页系统横空出世。分页系统的核心在于：**将虚拟内存空间和物理内存空间皆划分为大小相同的页面，如4KB、8KB或16KB等，并以页面作为内存空间的最小分配单位，一个程序的一个页面可以存放在任意一个物理页面里**。


  （1）解决空间浪费碎片化问题


  由于将虚拟内存空间和物理内存空间按照某种规定的大小进行分配，这里我们称之为页（Page），然后按照页进行内存分配，也就克服了外部碎片的问题。


  （2）解决程序大小受限问题


  程序增长有限是因为一个程序需要全部加载到内存才能运行，因此解决的办法就是使得一个程序无须全部加载就可以运行。使用分页也可以解决这个问题，只需将当前需要的页面放在内存里，其他暂时不用的页面放在磁盘上，这样一个程序同时占用内存和磁盘，其增长空间就大大增加了。而且，分页之后，如果一个程序需要更多的空间，给其分配一个新页即可（而无需将程序倒出倒进从而提高空间增长效率）。
  
![](https://images2015.cnblogs.com/blog/381412/201601/381412-20160102005851870-1563056466.jpg)


![](https://images2015.cnblogs.com/blog/381412/201601/381412-20160102010913635-662925378.jpg)


![](https://images2015.cnblogs.com/blog/381412/201601/381412-20160102011229870-1049211221.jpg)


![](http://c.biancheng.net/cpp/uploads/allimg/140701/1-140F102004L08.jpg)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEwOTIwODUyMDAsMTk3NTA2Mzg1MywtMz
QwMDkyMTAwLC01ODc4MTc2MzEsLTIwMzAyMjUzNzUsNzgxNTY1
MzQ2LC0xNDkxMjA2MTQ0LDE0MDEzNTkxMjgsMTE5NDMxOTM5MC
w3MDY1NTA0MDAsNjIxMDIzNDEwLC01MzYyMjAxMzEsLTc0MTc5
OTc5NSw5ODM1NTU3MzEsMjEyNzc2MjQyLC0xMDE4Mjc3Njg2LC
0xNTA0MTYwMjg3LDE2MDc5ODMwNjAsMjIwNDA1MjM1LDEzMzcx
MzYxMTVdfQ==
-->